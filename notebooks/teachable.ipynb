{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "362825ff-bf28-4c34-b394-1703eea09070",
   "metadata": {},
   "outputs": [],
   "source": [
    "import traitlets\n",
    "import ipywidgets.widgets as widgets\n",
    "from IPython.display import display\n",
    "from jetbot import Camera, bgr8_to_jpeg\n",
    "\n",
    "camera = Camera.instance(width=224, height=224, usb=0)\n",
    "\n",
    "image = widgets.Image(format='jpeg', width=400, height=400)  # this width and height doesn't necessarily have to match the camera\n",
    "\n",
    "camera_link = traitlets.dlink((camera, 'value'), (image, 'value'), transform=bgr8_to_jpeg)\n",
    "classfication_result_image = widgets.Textarea(\n",
    "            value=u'Result:=',\n",
    "            description=u'Classifcation',\n",
    "            disabled=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3c7fc799-e4e1-4117-b070-00b461b0b75c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "def rgba2rgb(rgba, background=(255,255,255)):\n",
    "    row, col, ch = rgba.shape\n",
    "    if ch == 3:\n",
    "        return rgba\n",
    "    assert ch == 4, \"RGBA image has 4 channels\"\n",
    "    rgb = np.zeros((row, col, 3), dtype='float32')\n",
    "    r, g, b, a = rgba[:,:,0], rgba[:,:,1], rgba[:,:,2], rgba[:,:,3]\n",
    "    a = np.asarray(a, dtype='float32') / 255.0\n",
    "    R, G, B = background\n",
    "    rgb[:,:,0] = r * a + (1.0 - a) * R\n",
    "    rgb[:,:,1] = g * a + (1.0 - a) * G\n",
    "    rgb[:,:,2] = b * a + (1.0 - a) * B\n",
    "    return np.asarray(rgb, dtype=\"uint8\")\n",
    "\n",
    "def preprocess(camera_value):\n",
    "    data = np.ndarray(shape=(1, 224, 224, 3), dtype=np.float32)\n",
    "    x = camera_value\n",
    "    x = cv2.resize(x, (224, 224))\n",
    "    x = cv2.cvtColor(x, cv2.COLOR_BGR2RGB)\n",
    "    x = np.asarray(x)\n",
    "    normalized_image_array = (x.astype(np.float32) / 127.0) - 1\n",
    "    data[0] = normalized_image_array\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d72ff6b6-7fa2-40fc-bd55-283189ae6e6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.load_model('keras_model.h5')\n",
    "np.set_printoptions(suppress=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee6c9949-ef4f-4960-9dd0-577e9838b91c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data = np.ndarray(shape=(1, 224, 224, 3), dtype=np.float32)\n",
    "#image = preprocess(camera.value)\n",
    "#image_array = np.asarray(image)\n",
    "#normalized_image_array = (image_array.astype(np.float32) / 127.0) - 1\n",
    "\n",
    "# Load the image into the array\n",
    "#data[0] = normalized_image_array\n",
    "\n",
    "# run the inference\n",
    "#prediction = model.predict(data)\n",
    "#print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a27b38ff-3a59-483b-ab6f-92ef6375d493",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "data, target = np.array_split(np.loadtxt('labels.txt', dtype=str), [-1], axis=1)\n",
    "\n",
    "label=target.flatten().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "af7b7026-ab02-4e74-ab2a-029b9b08ef58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c2d285909a143bc94afc571271cdf93",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(Image(value=b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x01\\x01\\x00\\x00\\x01\\x00\\x01\\x00\\xâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(widgets.VBox([\n",
    "    widgets.HBox([image, classfication_result_image]),\n",
    "]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7db10a2a-4720-4e7c-9703-5894edc4b184",
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute(change):\n",
    "    image = change['new']\n",
    "    classfication_result_image.value = ' '\n",
    "    prediction = model.predict(preprocess(camera.value))\n",
    "    a=prediction[0].argmax(0)\n",
    "    classfication_result_image.value = label[a]\n",
    "#    output = model_trt(preprocess(camera.value).half())[0].detach().cpu().float().numpy()\n",
    "#    mask=decode_segmap(output.argmax(0))\n",
    "    #mask = 1.0 * (output.argmax(0) == 15)\n",
    "    #m = mask[:, :, None]\n",
    "    #print(m.shape)\n",
    "    #print(image.shape)\n",
    "    #seg_image.value = bgr8_to_jpeg(mask[:, :, None] * image)\n",
    "    #today = datetime.now()\n",
    "\n",
    "    #classfication_result_image.value = \"Text\" + today.strftime(\"%d/%m/%Y %H:%M:%S\")\n",
    "    \n",
    "mask = execute({'new': camera.value})\n",
    "camera.observe(execute, names='value')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6d3e3c22-9bee-42cc-988c-4ce2196e0b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "camera.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9a92c9e3-07e8-4500-8a08-47a8b0ff4108",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "from PIL import Image, ImageOps\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1e4fecfc-181e-41e1-8beb-835bc08b86a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = load_model('keras_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "82bf7a55-05d4-4fa5-a05a-d9b008969fa1",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "type object 'TFLiteConverterV2' has no attribute 'from_keras_model_file'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-7f22e661d08c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mconverter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlite\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTFLiteConverter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_keras_model_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'keras_model.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: type object 'TFLiteConverterV2' has no attribute 'from_keras_model_file'"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model_file('keras_model.h5') \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ebbcc52-a95c-46e8-b237-71983a78f3e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfmodel = converter.convert() \n",
    "open ('model.tflite' , \"wb\") .write(tfmodel)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
